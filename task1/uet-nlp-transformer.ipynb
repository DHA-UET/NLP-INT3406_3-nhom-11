{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d464dc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:33:48.482890Z",
     "iopub.status.busy": "2025-12-16T17:33:48.482635Z",
     "iopub.status.idle": "2025-12-16T17:33:51.998307Z",
     "shell.execute_reply": "2025-12-16T17:33:51.997701Z"
    },
    "papermill": {
     "duration": 3.527639,
     "end_time": "2025-12-16T17:33:51.999726",
     "exception": false,
     "start_time": "2025-12-16T17:33:48.472087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import re\n",
    "import random\n",
    "import html\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c165725",
   "metadata": {
    "papermill": {
     "duration": 0.008136,
     "end_time": "2025-12-16T17:33:52.016446",
     "exception": false,
     "start_time": "2025-12-16T17:33:52.008310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Read & split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc684ff9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-16T17:33:52.033258Z",
     "iopub.status.busy": "2025-12-16T17:33:52.032807Z",
     "iopub.status.idle": "2025-12-16T17:33:52.038764Z",
     "shell.execute_reply": "2025-12-16T17:33:52.038074Z"
    },
    "papermill": {
     "duration": 0.015647,
     "end_time": "2025-12-16T17:33:52.039886",
     "exception": false,
     "start_time": "2025-12-16T17:33:52.024239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Decode HTML (&quot; -> \", &amp; -> &; ...)\n",
    "    text = html.unescape(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def read_pair_files(src_file_path, trg_file_path):\n",
    "    print(f\"Reading and Preprocessing data from: {src_file_path} and {trg_file_path}...\")\n",
    "\n",
    "    with open(src_file_path, 'r', encoding='utf-8') as f:\n",
    "        src_lines = f.read().strip().split('\\n')\n",
    "\n",
    "    with open(trg_file_path, 'r', encoding='utf-8') as f:\n",
    "        trg_lines = f.read().strip().split('\\n')\n",
    "\n",
    "    assert len(src_lines) == len(trg_lines), \"Error: Rows of source and target are different\"\n",
    "\n",
    "    dataset = []\n",
    "    \n",
    "    for src, trg in tqdm(zip(src_lines, trg_lines), total=len(src_lines)):\n",
    "        src_clean = preprocess_text(src)\n",
    "        trg_clean = preprocess_text(trg)\n",
    "        \n",
    "        if len(src_clean) > 0 and len(trg_clean) > 0:\n",
    "            dataset.append({'src': src_clean, 'trg': trg_clean})\n",
    "\n",
    "    print(f\"Done! Cleaned and read: {len(dataset)} rows.\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e038eca8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:33:52.056789Z",
     "iopub.status.busy": "2025-12-16T17:33:52.056592Z",
     "iopub.status.idle": "2025-12-16T17:33:55.257652Z",
     "shell.execute_reply": "2025-12-16T17:33:55.256795Z"
    },
    "papermill": {
     "duration": 3.211155,
     "end_time": "2025-12-16T17:33:55.258795",
     "exception": false,
     "start_time": "2025-12-16T17:33:52.047640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and Preprocessing data from: /kaggle/input/iwslt-15-en-vi/train.en.txt and /kaggle/input/iwslt-15-en-vi/train.vi.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133317/133317 [00:02<00:00, 51579.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Cleaned and read: 133166 rows.\n",
      "Reading and Preprocessing data from: /kaggle/input/iwslt-15-en-vi/tst2013.en.txt and /kaggle/input/iwslt-15-en-vi/tst2013.vi.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1268/1268 [00:00<00:00, 51951.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Cleaned and read: 1268 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_src_file = \"/kaggle/input/iwslt-15-en-vi/train.en.txt\"\n",
    "train_trg_file = \"/kaggle/input/iwslt-15-en-vi/train.vi.txt\"\n",
    "test_src_file = \"/kaggle/input/iwslt-15-en-vi/tst2013.en.txt\"\n",
    "test_trg_file = \"/kaggle/input/iwslt-15-en-vi/tst2013.vi.txt\"\n",
    "\n",
    "full_train_data = read_pair_files(train_src_file, train_trg_file)\n",
    "test_data = read_pair_files(test_src_file, test_trg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51a41f24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:33:55.278370Z",
     "iopub.status.busy": "2025-12-16T17:33:55.278149Z",
     "iopub.status.idle": "2025-12-16T17:33:55.331873Z",
     "shell.execute_reply": "2025-12-16T17:33:55.331134Z"
    },
    "papermill": {
     "duration": 0.064491,
     "end_time": "2025-12-16T17:33:55.332953",
     "exception": false,
     "start_time": "2025-12-16T17:33:55.268462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split: Train=119849, Valid=13317, Test=1268\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(full_train_data)\n",
    "split_ratio = 0.9\n",
    "split_idx = int(len(full_train_data) * split_ratio)\n",
    "\n",
    "train_data = full_train_data[:split_idx]\n",
    "valid_data = full_train_data[split_idx:]\n",
    "\n",
    "print(f\"Data split: Train={len(train_data)}, Valid={len(valid_data)}, Test={len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb94a66",
   "metadata": {
    "papermill": {
     "duration": 0.009245,
     "end_time": "2025-12-16T17:33:55.351580",
     "exception": false,
     "start_time": "2025-12-16T17:33:55.342335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Vocabulary & dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dceb7970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:33:55.371106Z",
     "iopub.status.busy": "2025-12-16T17:33:55.370855Z",
     "iopub.status.idle": "2025-12-16T17:33:55.376268Z",
     "shell.execute_reply": "2025-12-16T17:33:55.375634Z"
    },
    "papermill": {
     "duration": 0.016652,
     "end_time": "2025-12-16T17:33:55.377287",
     "exception": false,
     "start_time": "2025-12-16T17:33:55.360635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.stoi = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3}\n",
    "        self.itos = {0: '<pad>', 1: '<sos>', 2: '<eos>', 3: '<unk>'}\n",
    "        self.freq_threshold = 2\n",
    "\n",
    "    def tokenizer(self, text):\n",
    "        text = text.lower().strip()\n",
    "        return re.findall(r\"\\w+|[^\\w\\s]\", text)\n",
    "\n",
    "    def build_vocabulary(self, sentence_list):\n",
    "        frequencies = Counter()\n",
    "        idx = 4\n",
    "        for sentence in sentence_list:\n",
    "            for word in self.tokenizer(sentence):\n",
    "                frequencies[word] += 1\n",
    "                if frequencies[word] == self.freq_threshold:\n",
    "                    self.stoi[word] = idx\n",
    "                    self.itos[idx] = word\n",
    "                    idx += 1\n",
    "\n",
    "    def numericalize(self, text):\n",
    "        tokenized_text = self.tokenizer(text)\n",
    "        return [self.stoi.get(token, self.stoi['<unk>']) for token in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1311b7bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:33:55.396671Z",
     "iopub.status.busy": "2025-12-16T17:33:55.396080Z",
     "iopub.status.idle": "2025-12-16T17:33:58.742411Z",
     "shell.execute_reply": "2025-12-16T17:33:58.741599Z"
    },
    "papermill": {
     "duration": 3.35711,
     "end_time": "2025-12-16T17:33:58.743635",
     "exception": false,
     "start_time": "2025-12-16T17:33:55.386525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocabulary...\n",
      "Vocab Size -> En: 26690, Vi: 11278\n"
     ]
    }
   ],
   "source": [
    "print(\"Building vocabulary...\")\n",
    "src_vocab = Vocabulary()\n",
    "trg_vocab = Vocabulary()\n",
    "\n",
    "src_texts = [item['src'] for item in train_data]\n",
    "trg_texts = [item['trg'] for item in train_data]\n",
    "\n",
    "src_vocab.build_vocabulary(src_texts)\n",
    "trg_vocab.build_vocabulary(trg_texts)\n",
    "\n",
    "print(f\"Vocab Size -> En: {len(src_vocab.stoi)}, Vi: {len(trg_vocab.stoi)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bba3ffb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:33:58.763541Z",
     "iopub.status.busy": "2025-12-16T17:33:58.763322Z",
     "iopub.status.idle": "2025-12-16T17:33:58.769080Z",
     "shell.execute_reply": "2025-12-16T17:33:58.768515Z"
    },
    "papermill": {
     "duration": 0.01664,
     "end_time": "2025-12-16T17:33:58.770082",
     "exception": false,
     "start_time": "2025-12-16T17:33:58.753442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ManualDataset(Dataset):\n",
    "    def __init__(self, data, src_vocab, trg_vocab):\n",
    "        self.data = data\n",
    "        self.src_vocab = src_vocab\n",
    "        self.trg_vocab = trg_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        pair = self.data[index]\n",
    "        src_text = pair['src']\n",
    "        trg_text = pair['trg']\n",
    "\n",
    "        # [SOS] + [Indices] + [EOS]\n",
    "        src_indices = [1] + self.src_vocab.numericalize(src_text) + [2]\n",
    "        trg_indices = [1] + self.trg_vocab.numericalize(trg_text) + [2]\n",
    "\n",
    "        return torch.tensor(src_indices), torch.tensor(trg_indices)\n",
    "\n",
    "class Collate:\n",
    "    def __init__(self, pad_idx):\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        src_batch, trg_batch = zip(*batch)\n",
    "        # Dynamic batch padding, only pad to size of the largest in batch\n",
    "        src_batch = torch.nn.utils.rnn.pad_sequence(src_batch, padding_value=self.pad_idx, batch_first=True)\n",
    "        trg_batch = torch.nn.utils.rnn.pad_sequence(trg_batch, padding_value=self.pad_idx, batch_first=True)\n",
    "        return src_batch, trg_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56bb332",
   "metadata": {
    "papermill": {
     "duration": 0.00907,
     "end_time": "2025-12-16T17:33:58.788552",
     "exception": false,
     "start_time": "2025-12-16T17:33:58.779482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transformer Architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd35f442",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:33:58.807870Z",
     "iopub.status.busy": "2025-12-16T17:33:58.807629Z",
     "iopub.status.idle": "2025-12-16T17:33:58.826094Z",
     "shell.execute_reply": "2025-12-16T17:33:58.825557Z"
    },
    "papermill": {
     "duration": 0.029504,
     "end_time": "2025-12-16T17:33:58.827182",
     "exception": false,
     "start_time": "2025-12-16T17:33:58.797678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class TransformerEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, max_len=5000, drop_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Input/Output Embedding\n",
    "        self.tok_emb = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # Positional Encoding\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        # Sin PE\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0)) # no update gradient\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (Batch, Seq_Len)\n",
    "        token_emb = self.tok_emb(x) * math.sqrt(self.d_model)\n",
    "        # 2. Add PE\n",
    "        pos_emb = self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(token_emb + pos_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d87d325a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:33:58.846524Z",
     "iopub.status.busy": "2025-12-16T17:33:58.846319Z",
     "iopub.status.idle": "2025-12-16T17:33:58.853054Z",
     "shell.execute_reply": "2025-12-16T17:33:58.852354Z"
    },
    "papermill": {
     "duration": 0.017617,
     "end_time": "2025-12-16T17:33:58.854097",
     "exception": false,
     "start_time": "2025-12-16T17:33:58.836480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_head):\n",
    "        super().__init__()\n",
    "        self.n_head = n_head\n",
    "        self.head_dim = d_model // n_head\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Q, K, V\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # Linear\n",
    "        self.fc_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        # q, k, v: (Batch, Seq_Len, d_model)\n",
    "        batch_size = q.size(0)\n",
    "\n",
    "        # 1. Linear Project & Split Heads\n",
    "        # d_model -> n_head x head_dim\n",
    "        Q = self.w_q(q).view(batch_size, -1, self.n_head, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = self.w_k(k).view(batch_size, -1, self.n_head, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = self.w_v(v).view(batch_size, -1, self.n_head, self.head_dim).permute(0, 2, 1, 3)\n",
    "\n",
    "        # 2. Scaled Dot-Product Attention\n",
    "        # Energy: Q * K^T / sqrt(head_dim)\n",
    "        energy = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
    "\n",
    "        # 3. Apply Mask\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        # 4. Softmax & Weighted Sum\n",
    "        attention = torch.softmax(energy, dim=-1)\n",
    "        x = torch.matmul(attention, V) # (Batch, n_head, Seq_Len, head_dim)\n",
    "\n",
    "        # 5. Concat Heads & Final Linear\n",
    "        x = x.permute(0, 2, 1, 3).contiguous().view(batch_size, -1, self.d_model)\n",
    "        return self.fc_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5829673f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:33:58.873254Z",
     "iopub.status.busy": "2025-12-16T17:33:58.873016Z",
     "iopub.status.idle": "2025-12-16T17:33:58.877225Z",
     "shell.execute_reply": "2025-12-16T17:33:58.876683Z"
    },
    "papermill": {
     "duration": 0.014902,
     "end_time": "2025-12-16T17:33:58.878204",
     "exception": false,
     "start_time": "2025-12-16T17:33:58.863302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # Linear -> ReLU -> Linear\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.dropout(self.relu(self.fc1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a9d8290",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:33:58.897267Z",
     "iopub.status.busy": "2025-12-16T17:33:58.897080Z",
     "iopub.status.idle": "2025-12-16T17:33:58.902090Z",
     "shell.execute_reply": "2025-12-16T17:33:58.901414Z"
    },
    "papermill": {
     "duration": 0.015678,
     "end_time": "2025-12-16T17:33:58.903084",
     "exception": false,
     "start_time": "2025-12-16T17:33:58.887406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_head, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        # Sub-layer 1: Self Attention\n",
    "        self.self_attn = MultiHeadAttention(d_model, n_head)\n",
    "        self.norm1 = nn.LayerNorm(d_model) # Add & Norm\n",
    "\n",
    "        # Sub-layer 2: Feed Forward\n",
    "        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.norm2 = nn.LayerNorm(d_model) # Add & Norm\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        # 1. Self-Attention: Multi-Head attention with all Q,K,V from src\n",
    "        _src = self.self_attn(src, src, src, src_mask)\n",
    "\n",
    "        # Add & Norm (Residual)\n",
    "        src = self.norm1(src + self.dropout(_src))\n",
    "\n",
    "        # 2. Feed Forward\n",
    "        _src = self.ffn(src)\n",
    "\n",
    "        # Add & Norm\n",
    "        src = self.norm2(src + self.dropout(_src))\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8740cd72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:33:58.922365Z",
     "iopub.status.busy": "2025-12-16T17:33:58.921948Z",
     "iopub.status.idle": "2025-12-16T17:33:58.927123Z",
     "shell.execute_reply": "2025-12-16T17:33:58.926595Z"
    },
    "papermill": {
     "duration": 0.015819,
     "end_time": "2025-12-16T17:33:58.928120",
     "exception": false,
     "start_time": "2025-12-16T17:33:58.912301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_head, d_ff, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # Sub-layer 1: Masked Self-Attention\n",
    "        self.self_attn = MultiHeadAttention(d_model, n_head)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Sub-layer 2: Cross-Attention\n",
    "        self.cross_attn = MultiHeadAttention(d_model, n_head)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Sub-layer 3: Feed Forward\n",
    "        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        # 1. Masked Self-Attention\n",
    "        # Q, K, V from src. Mask: future mask\n",
    "        _trg = self.self_attn(trg, trg, trg, trg_mask)\n",
    "        trg = self.norm1(trg + self.dropout(_trg))\n",
    "\n",
    "        # 2. Cross-Attention (Encoder-Decoder Attention)\n",
    "        # Q: target (Decoder), K,V: source (Encoder)\n",
    "        _trg = self.cross_attn(trg, enc_src, enc_src, src_mask)\n",
    "        trg = self.norm2(trg + self.dropout(_trg))\n",
    "\n",
    "        # 3. Feed Forward\n",
    "        _trg = self.ffn(trg)\n",
    "        trg = self.norm3(trg + self.dropout(_trg))\n",
    "\n",
    "        return trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99f4fcae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:33:58.947760Z",
     "iopub.status.busy": "2025-12-16T17:33:58.947586Z",
     "iopub.status.idle": "2025-12-16T17:33:58.954756Z",
     "shell.execute_reply": "2025-12-16T17:33:58.954242Z"
    },
    "papermill": {
     "duration": 0.018389,
     "end_time": "2025-12-16T17:33:58.955734",
     "exception": false,
     "start_time": "2025-12-16T17:33:58.937345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_vocab_size, trg_vocab_size,\n",
    "        src_pad_idx, trg_pad_idx,\n",
    "        d_model=512, n_head=8, n_layer=6, d_ff=2048,\n",
    "        dropout=0.1, device=\"cuda\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "\n",
    "        # 1. Input Embeddings & Positional Encoding\n",
    "        self.src_embedding = TransformerEmbedding(src_vocab_size, d_model, drop_prob=dropout)\n",
    "        self.trg_embedding = TransformerEmbedding(trg_vocab_size, d_model, drop_prob=dropout)\n",
    "\n",
    "        # 2. Encoder (Nx)\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, n_head, d_ff, dropout) for _ in range(n_layer)\n",
    "        ])\n",
    "\n",
    "        # 3. Decoder (Nx)\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, n_head, d_ff, dropout) for _ in range(n_layer)\n",
    "        ])\n",
    "\n",
    "        # 4. Linear & Softmax\n",
    "        # PyTorch CrossEntropyLoss included Softmax\n",
    "        self.fc_out = nn.Linear(d_model, trg_vocab_size)\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        # padding mask\n",
    "        # Shape: (Batch, 1, 1, Src_Len)\n",
    "        return (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2).to(self.device)\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        # padding mask\n",
    "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # future mask\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device=self.device)).bool()\n",
    "\n",
    "        return (trg_pad_mask & trg_sub_mask).to(self.device)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        # src: (Batch, Src_Len) -> Inputs\n",
    "        # trg: (Batch, Trg_Len) -> Outputs (shifted right)\n",
    "\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "\n",
    "        # --- Encoder Flow ---\n",
    "        # 1. Input -> Embedding + Positional Encoding\n",
    "        enc_src = self.src_embedding(src)\n",
    "\n",
    "        # 2. Nx Encoder\n",
    "        for layer in self.encoder_layers:\n",
    "            enc_src = layer(enc_src, src_mask)\n",
    "\n",
    "        # --- Decoder Flow ---\n",
    "        # 3. Output (shifted) -> Embedding + Positional Encoding\n",
    "        output = self.trg_embedding(trg)\n",
    "\n",
    "        # 4. Nx Decoder\n",
    "        for layer in self.decoder_layers:\n",
    "            output = layer(output, enc_src, trg_mask, src_mask)\n",
    "\n",
    "        # 5. Output Probabilities\n",
    "        return self.fc_out(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628ead33",
   "metadata": {
    "papermill": {
     "duration": 0.009488,
     "end_time": "2025-12-16T17:33:58.974568",
     "exception": false,
     "start_time": "2025-12-16T17:33:58.965080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MT Transformer Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6c993fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:33:58.994022Z",
     "iopub.status.busy": "2025-12-16T17:33:58.993798Z",
     "iopub.status.idle": "2025-12-16T17:34:01.658085Z",
     "shell.execute_reply": "2025-12-16T17:34:01.657313Z"
    },
    "papermill": {
     "duration": 2.675874,
     "end_time": "2025-12-16T17:34:01.659500",
     "exception": false,
     "start_time": "2025-12-16T17:33:58.983626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "from collections import Counter\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce227c91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:34:01.679430Z",
     "iopub.status.busy": "2025-12-16T17:34:01.679094Z",
     "iopub.status.idle": "2025-12-16T17:34:01.731890Z",
     "shell.execute_reply": "2025-12-16T17:34:01.731317Z"
    },
    "papermill": {
     "duration": 0.063867,
     "end_time": "2025-12-16T17:34:01.732961",
     "exception": false,
     "start_time": "2025-12-16T17:34:01.669094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Hyperparameters ---\n",
    "BATCH_SIZE = 16\n",
    "D_MODEL = 256   # 512\n",
    "N_HEAD = 4      # 8\n",
    "N_LAYER = 4     # 6\n",
    "D_FF = 1024     # 2048\n",
    "DROPOUT = 0.1\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0001\n",
    "MAX_LEN = 100\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b37e40e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:34:01.753234Z",
     "iopub.status.busy": "2025-12-16T17:34:01.752994Z",
     "iopub.status.idle": "2025-12-16T17:34:06.309472Z",
     "shell.execute_reply": "2025-12-16T17:34:06.308864Z"
    },
    "papermill": {
     "duration": 4.568318,
     "end_time": "2025-12-16T17:34:06.310768",
     "exception": false,
     "start_time": "2025-12-16T17:34:01.742450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Model ---\n",
    "model = Transformer(\n",
    "    src_vocab_size=len(src_vocab.stoi),\n",
    "    trg_vocab_size=len(trg_vocab.stoi),\n",
    "    src_pad_idx=0,\n",
    "    trg_pad_idx=0,\n",
    "    d_model=D_MODEL,\n",
    "    n_head=N_HEAD,\n",
    "    n_layer=N_LAYER,\n",
    "    d_ff=D_FF,\n",
    "    dropout=DROPOUT,\n",
    "    device=DEVICE\n",
    ").to(DEVICE)\n",
    "\n",
    "# --- Weights ---\n",
    "# Xavier Initialization\n",
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "model.apply(initialize_weights)\n",
    "\n",
    "# --- Optimizer & Scheduler ---\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "# Loss Function\n",
    "# ignore_index=0 ignore loss <pad> token\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd09d456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:34:06.333082Z",
     "iopub.status.busy": "2025-12-16T17:34:06.332711Z",
     "iopub.status.idle": "2025-12-16T17:34:06.344006Z",
     "shell.execute_reply": "2025-12-16T17:34:06.343468Z"
    },
    "papermill": {
     "duration": 0.024534,
     "end_time": "2025-12-16T17:34:06.345080",
     "exception": false,
     "start_time": "2025-12-16T17:34:06.320546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, (src, trg) in tqdm(enumerate(iterator), total=len(iterator)):\n",
    "        src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # trg input: ignore <eos>\n",
    "        # trg output ignore <sos>\n",
    "        output = model(src, trg[:, :-1]) # (Batch, Seq_Len-1, Vocab_Size)\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        # Flatten for calc Loss\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trg = trg[:, 1:].contiguous().view(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient Clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (src, trg) in enumerate(iterator):\n",
    "            src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
    "            output = model(src, trg[:, :-1])\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:, 1:].contiguous().view(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "# --- Inference ---\n",
    "def translate_sentence(sentence, src_vocab, trg_vocab, model, device, max_len=50):\n",
    "    model.eval()\n",
    "\n",
    "    tokens = src_vocab.tokenizer(sentence)\n",
    "    src_indexes = [src_vocab.stoi['<sos>']] + \\\n",
    "                  [src_vocab.stoi.get(token, src_vocab.stoi['<unk>']) for token in tokens] + \\\n",
    "                  [src_vocab.stoi['<eos>']]\n",
    "\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "    src_mask = model.make_src_mask(src_tensor)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        enc_src = model.src_embedding(src_tensor)\n",
    "        for layer in model.encoder_layers:\n",
    "            enc_src = layer(enc_src, src_mask)\n",
    "\n",
    "        trg_indexes = [trg_vocab.stoi['<sos>']]\n",
    "\n",
    "        for i in range(max_len):\n",
    "            trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "            trg_mask = model.make_trg_mask(trg_tensor)\n",
    "\n",
    "            output = model.trg_embedding(trg_tensor)\n",
    "            for layer in model.decoder_layers:\n",
    "                output = layer(output, enc_src, trg_mask, src_mask)\n",
    "\n",
    "            output = model.fc_out(output)\n",
    "            pred_token = output.argmax(2)[:,-1].item()\n",
    "\n",
    "            trg_indexes.append(pred_token)\n",
    "            if pred_token == trg_vocab.stoi['<eos>']:\n",
    "                break\n",
    "\n",
    "    trg_tokens = [trg_vocab.itos[i] for i in trg_indexes]\n",
    "    return trg_tokens[1:-1] # ignore sos, eos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11a3c462",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:34:06.364193Z",
     "iopub.status.busy": "2025-12-16T17:34:06.363967Z",
     "iopub.status.idle": "2025-12-16T17:34:06.367249Z",
     "shell.execute_reply": "2025-12-16T17:34:06.366592Z"
    },
    "papermill": {
     "duration": 0.013975,
     "end_time": "2025-12-16T17:34:06.368247",
     "exception": false,
     "start_time": "2025-12-16T17:34:06.354272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e008cab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:34:06.387383Z",
     "iopub.status.busy": "2025-12-16T17:34:06.387180Z",
     "iopub.status.idle": "2025-12-16T17:34:06.391714Z",
     "shell.execute_reply": "2025-12-16T17:34:06.391062Z"
    },
    "papermill": {
     "duration": 0.015365,
     "end_time": "2025-12-16T17:34:06.392782",
     "exception": false,
     "start_time": "2025-12-16T17:34:06.377417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = ManualDataset(train_data, src_vocab, trg_vocab)\n",
    "valid_ds = ManualDataset(valid_data, src_vocab, trg_vocab)\n",
    "test_ds  = ManualDataset(test_data, src_vocab, trg_vocab)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=Collate(pad_idx=0))\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=Collate(pad_idx=0))\n",
    "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=Collate(pad_idx=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "632cfda6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:34:06.412231Z",
     "iopub.status.busy": "2025-12-16T17:34:06.411992Z",
     "iopub.status.idle": "2025-12-16T18:16:27.354626Z",
     "shell.execute_reply": "2025-12-16T18:16:27.353664Z"
    },
    "papermill": {
     "duration": 2541.693629,
     "end_time": "2025-12-16T18:16:28.095700",
     "exception": false,
     "start_time": "2025-12-16T17:34:06.402071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:05<00:00, 30.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model (Val Loss: 4.249)\n",
      "Epoch: 01 | Time: 4m 14s\n",
      "\tTrain Loss: 4.980 | Train PPL: 145.523\n",
      "\t Val. Loss: 4.249 |  Val. PPL:  70.017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:03<00:00, 30.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model (Val Loss: 3.488)\n",
      "Epoch: 02 | Time: 4m 12s\n",
      "\tTrain Loss: 3.950 | Train PPL:  51.945\n",
      "\t Val. Loss: 3.488 |  Val. PPL:  32.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:04<00:00, 30.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model (Val Loss: 3.042)\n",
      "Epoch: 03 | Time: 4m 13s\n",
      "\tTrain Loss: 3.388 | Train PPL:  29.595\n",
      "\t Val. Loss: 3.042 |  Val. PPL:  20.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:05<00:00, 30.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model (Val Loss: 2.745)\n",
      "Epoch: 04 | Time: 4m 14s\n",
      "\tTrain Loss: 3.012 | Train PPL:  20.329\n",
      "\t Val. Loss: 2.745 |  Val. PPL:  15.560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:04<00:00, 30.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model (Val Loss: 2.573)\n",
      "Epoch: 05 | Time: 4m 13s\n",
      "\tTrain Loss: 2.759 | Train PPL:  15.787\n",
      "\t Val. Loss: 2.573 |  Val. PPL:  13.110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:05<00:00, 30.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model (Val Loss: 2.467)\n",
      "Epoch: 06 | Time: 4m 13s\n",
      "\tTrain Loss: 2.583 | Train PPL:  13.242\n",
      "\t Val. Loss: 2.467 |  Val. PPL:  11.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:04<00:00, 30.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model (Val Loss: 2.386)\n",
      "Epoch: 07 | Time: 4m 13s\n",
      "\tTrain Loss: 2.456 | Train PPL:  11.660\n",
      "\t Val. Loss: 2.386 |  Val. PPL:  10.874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:05<00:00, 30.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model (Val Loss: 2.330)\n",
      "Epoch: 08 | Time: 4m 14s\n",
      "\tTrain Loss: 2.356 | Train PPL:  10.553\n",
      "\t Val. Loss: 2.330 |  Val. PPL:  10.280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:06<00:00, 30.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model (Val Loss: 2.299)\n",
      "Epoch: 09 | Time: 4m 14s\n",
      "\tTrain Loss: 2.283 | Train PPL:   9.810\n",
      "\t Val. Loss: 2.299 |  Val. PPL:   9.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:04<00:00, 30.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model (Val Loss: 2.258)\n",
      "Epoch: 10 | Time: 4m 13s\n",
      "\tTrain Loss: 2.221 | Train PPL:   9.214\n",
      "\t Val. Loss: 2.258 |  Val. PPL:   9.562\n"
     ]
    }
   ],
   "source": [
    "# --- MAIN LOOP ---\n",
    "CLIP = 1\n",
    "best_valid_loss = float('inf')\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "train_ppls = []\n",
    "valid_ppls = []\n",
    "\n",
    "print(f\"Start Training on {DEVICE}...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_loader, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = divmod(end_time - start_time, 60)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    train_ppls.append(math.exp(train_loss))\n",
    "    valid_ppls.append(math.exp(valid_loss))\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'transformer-model.pt')\n",
    "        print(f\"Saved Model (Val Loss: {valid_loss:.3f})\")\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {int(epoch_mins)}m {int(epoch_secs)}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1df61f61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:16:29.656695Z",
     "iopub.status.busy": "2025-12-16T18:16:29.655930Z",
     "iopub.status.idle": "2025-12-16T18:16:29.876781Z",
     "shell.execute_reply": "2025-12-16T18:16:29.876074Z"
    },
    "papermill": {
     "duration": 0.955356,
     "end_time": "2025-12-16T18:16:29.878005",
     "exception": false,
     "start_time": "2025-12-16T18:16:28.922649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(valid_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "694225dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:16:31.481782Z",
     "iopub.status.busy": "2025-12-16T18:16:31.481493Z",
     "iopub.status.idle": "2025-12-16T18:16:31.562132Z",
     "shell.execute_reply": "2025-12-16T18:16:31.561289Z"
    },
    "papermill": {
     "duration": 0.819416,
     "end_time": "2025-12-16T18:16:31.563392",
     "exception": false,
     "start_time": "2025-12-16T18:16:30.743976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Translation ---\n",
      "Input: hello world\n",
      "Output: xin chào thế giới .\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Testing Translation ---\")\n",
    "sample_sentence = \"hello world\"\n",
    "translation = translate_sentence(sample_sentence, src_vocab, trg_vocab, model, DEVICE)\n",
    "print(f\"Input: {sample_sentence}\")\n",
    "print(f\"Output: {' '.join(translation)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9fecd40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:16:33.161658Z",
     "iopub.status.busy": "2025-12-16T18:16:33.161071Z",
     "iopub.status.idle": "2025-12-16T18:16:33.220546Z",
     "shell.execute_reply": "2025-12-16T18:16:33.219683Z"
    },
    "papermill": {
     "duration": 0.803376,
     "end_time": "2025-12-16T18:16:33.221704",
     "exception": false,
     "start_time": "2025-12-16T18:16:32.418328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Translation ---\n",
      "Input: Attention is all you need\n",
      "Output: sự chú ý là tất cả các bạn cần .\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Testing Translation ---\")\n",
    "sample_sentence = \"Attention is all you need\"\n",
    "translation = translate_sentence(sample_sentence, src_vocab, trg_vocab, model, DEVICE)\n",
    "print(f\"Input: {sample_sentence}\")\n",
    "print(f\"Output: {' '.join(translation)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667f82ec",
   "metadata": {
    "papermill": {
     "duration": 0.734635,
     "end_time": "2025-12-16T18:16:34.789369",
     "exception": false,
     "start_time": "2025-12-16T18:16:34.054734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e34d24e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:16:36.364142Z",
     "iopub.status.busy": "2025-12-16T18:16:36.363854Z",
     "iopub.status.idle": "2025-12-16T18:16:38.093962Z",
     "shell.execute_reply": "2025-12-16T18:16:38.093395Z"
    },
    "papermill": {
     "duration": 2.471067,
     "end_time": "2025-12-16T18:16:38.095426",
     "exception": false,
     "start_time": "2025-12-16T18:16:35.624359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ac1ae53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:16:39.663517Z",
     "iopub.status.busy": "2025-12-16T18:16:39.663076Z",
     "iopub.status.idle": "2025-12-16T18:16:39.757885Z",
     "shell.execute_reply": "2025-12-16T18:16:39.757213Z"
    },
    "papermill": {
     "duration": 0.834129,
     "end_time": "2025-12-16T18:16:39.759112",
     "exception": false,
     "start_time": "2025-12-16T18:16:38.924983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('transformer-model.pt', map_location=DEVICE))\n",
    "model.eval()\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83b5232f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:16:41.375124Z",
     "iopub.status.busy": "2025-12-16T18:16:41.374815Z",
     "iopub.status.idle": "2025-12-16T18:16:41.381889Z",
     "shell.execute_reply": "2025-12-16T18:16:41.381208Z"
    },
    "papermill": {
     "duration": 0.742822,
     "end_time": "2025-12-16T18:16:41.383016",
     "exception": false,
     "start_time": "2025-12-16T18:16:40.640194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_vocab, trg_vocab, model, device, max_len=50):\n",
    "    model.eval()\n",
    "\n",
    "    if isinstance(sentence, str):\n",
    "        tokens = src_vocab.tokenizer(sentence)\n",
    "    else:\n",
    "        tokens = sentence\n",
    "\n",
    "    src_indexes = [src_vocab.stoi['<sos>']] + \\\n",
    "                  [src_vocab.stoi.get(token, src_vocab.stoi['<unk>']) for token in tokens] + \\\n",
    "                  [src_vocab.stoi['<eos>']]\n",
    "\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "    src_mask = model.make_src_mask(src_tensor)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        enc_src = model.src_embedding(src_tensor)\n",
    "        for layer in model.encoder_layers:\n",
    "            enc_src = layer(enc_src, src_mask)\n",
    "\n",
    "        # Decoding\n",
    "        trg_indexes = [trg_vocab.stoi['<sos>']]\n",
    "\n",
    "        for i in range(max_len):\n",
    "            trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "            trg_mask = model.make_trg_mask(trg_tensor)\n",
    "\n",
    "            output = model.trg_embedding(trg_tensor)\n",
    "            for layer in model.decoder_layers:\n",
    "                output = layer(output, enc_src, trg_mask, src_mask)\n",
    "\n",
    "            # Predict\n",
    "            output = model.fc_out(output)\n",
    "            pred_token = output.argmax(2)[:,-1].item()\n",
    "\n",
    "            trg_indexes.append(pred_token)\n",
    "\n",
    "            # <eos>\n",
    "            if pred_token == trg_vocab.stoi['<eos>']:\n",
    "                break\n",
    "\n",
    "    # Index to string\n",
    "    trg_tokens = [trg_vocab.itos[i] for i in trg_indexes]\n",
    "\n",
    "    # remove <sos> và <eos>\n",
    "    return trg_tokens[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a301ede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:16:42.983956Z",
     "iopub.status.busy": "2025-12-16T18:16:42.983170Z",
     "iopub.status.idle": "2025-12-16T18:16:42.988460Z",
     "shell.execute_reply": "2025-12-16T18:16:42.987919Z"
    },
    "papermill": {
     "duration": 0.753538,
     "end_time": "2025-12-16T18:16:42.989591",
     "exception": false,
     "start_time": "2025-12-16T18:16:42.236053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_bleu(data, src_vocab, trg_vocab, model, device):\n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "\n",
    "    print(f\"BLEU in {len(data)} test rows\")\n",
    "\n",
    "    for i, example in enumerate(data):\n",
    "        src = example['src']\n",
    "        trg = example['trg']\n",
    "\n",
    "        pred_trg = translate_sentence(src, src_vocab, trg_vocab, model, device)\n",
    "\n",
    "        if isinstance(trg, str):\n",
    "            trg_tokenized = trg_vocab.tokenizer(trg)\n",
    "        else:\n",
    "            trg_tokenized = trg\n",
    "\n",
    "        pred_trgs.append(pred_trg)\n",
    "        trgs.append([trg_tokenized]) # Fix: BLEU need list of lists for references\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(f\"--- Sentence: {i} ---\")\n",
    "            print(f\"Src : {src}\")\n",
    "            print(f\"Trg : {trg}\")\n",
    "            print(f\"Pred: {' '.join(pred_trg)}\")\n",
    "\n",
    "    score = corpus_bleu(trgs, pred_trgs)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98f9ab0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:16:44.569327Z",
     "iopub.status.busy": "2025-12-16T18:16:44.568715Z",
     "iopub.status.idle": "2025-12-16T18:19:14.120123Z",
     "shell.execute_reply": "2025-12-16T18:19:14.119281Z"
    },
    "papermill": {
     "duration": 151.135161,
     "end_time": "2025-12-16T18:19:14.864055",
     "exception": false,
     "start_time": "2025-12-16T18:16:43.728894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU in 1268 test rows\n",
      "--- Sentence: 0 ---\n",
      "Src : when i was little , i thought my country was the best on the planet , and i grew up singing a song called \" nothing to envy . \"\n",
      "Trg : khi tôi còn nhỏ , tôi nghĩ rằng bắctriều tiên là đất nước tốt nhất trên thế giới và tôi thường hát bài \" chúng ta chẳng có gì phải ghen tị . \"\n",
      "Pred: khi tôi còn nhỏ , tôi nghĩ đất nước tôi là người tốt nhất trên hành tinh , và tôi lớn lên hát một bài hát gọi là \" không có gì để làm phiền . \"\n",
      "--- Sentence: 500 ---\n",
      "Src : back then , we had no idea how much this trip would change our lives .\n",
      "Trg : hồi đó , chúng tôi không hề biết chuyến đi ấy sẽ thay đổi cuộc sống của chúng tôi như thế nào .\n",
      "Pred: quay lại , chúng tôi không biết chuyến đi này sẽ thay đổi cuộc sống của chúng tôi bao nhiêu .\n",
      "--- Sentence: 1000 ---\n",
      "Src : so planning has this blind spot .\n",
      "Trg : vậy nên hoạch định có một điểm mù này .\n",
      "Pred: vì vậy , kế hoạch đã có một điểm mù .\n",
      "\n",
      "BLEU score = 24.61\n"
     ]
    }
   ],
   "source": [
    "bleu_score = calculate_bleu(test_data, src_vocab, trg_vocab, model, DEVICE)\n",
    "print(f'\\nBLEU score = {bleu_score*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6faf305",
   "metadata": {
    "papermill": {
     "duration": 0.740467,
     "end_time": "2025-12-16T18:19:16.434815",
     "exception": false,
     "start_time": "2025-12-16T18:19:15.694348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Optim 1: Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66132f04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:19:18.027687Z",
     "iopub.status.busy": "2025-12-16T18:19:18.027428Z",
     "iopub.status.idle": "2025-12-16T18:19:18.030818Z",
     "shell.execute_reply": "2025-12-16T18:19:18.030229Z"
    },
    "papermill": {
     "duration": 0.74696,
     "end_time": "2025-12-16T18:19:18.031824",
     "exception": false,
     "start_time": "2025-12-16T18:19:17.284864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cab2d06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:19:19.604172Z",
     "iopub.status.busy": "2025-12-16T18:19:19.603890Z",
     "iopub.status.idle": "2025-12-16T18:19:19.613325Z",
     "shell.execute_reply": "2025-12-16T18:19:19.612781Z"
    },
    "papermill": {
     "duration": 0.749905,
     "end_time": "2025-12-16T18:19:19.614491",
     "exception": false,
     "start_time": "2025-12-16T18:19:18.864586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate_sentence_beam(sentence, src_vocab, trg_vocab, model, device, max_len=50, beam_size=3, alpha=0.7):\n",
    "    model.eval()\n",
    "\n",
    "    if isinstance(sentence, str):\n",
    "        tokens = src_vocab.tokenizer(sentence)\n",
    "    else:\n",
    "        tokens = sentence\n",
    "\n",
    "    src_indexes = [src_vocab.stoi['<sos>']] + \\\n",
    "                  [src_vocab.stoi.get(token, src_vocab.stoi['<unk>']) for token in tokens] + \\\n",
    "                  [src_vocab.stoi['<eos>']]\n",
    "\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device) # (1, Src_Len)\n",
    "    src_mask = model.make_src_mask(src_tensor)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        enc_src = model.src_embedding(src_tensor)\n",
    "        for layer in model.encoder_layers:\n",
    "            enc_src = layer(enc_src, src_mask)\n",
    "\n",
    "    sos_idx = trg_vocab.stoi['<sos>']\n",
    "    eos_idx = trg_vocab.stoi['<eos>']\n",
    "\n",
    "    beam = [([sos_idx], 0.0)]\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        candidates = []\n",
    "        for seq, score in beam:\n",
    "            if seq[-1] == eos_idx:\n",
    "                norm_score = score / (len(seq) ** alpha)\n",
    "                candidates.append((seq, norm_score, True))\n",
    "                continue\n",
    "\n",
    "            trg_tensor = torch.LongTensor(seq).unsqueeze(0).to(device)\n",
    "            trg_mask = model.make_trg_mask(trg_tensor)\n",
    "\n",
    "            # Decoder\n",
    "            with torch.no_grad():\n",
    "                output = model.trg_embedding(trg_tensor)\n",
    "                for layer in model.decoder_layers:\n",
    "                    output = layer(output, enc_src, trg_mask, src_mask)\n",
    "\n",
    "                output = model.fc_out(output)\n",
    "                # shape: (1, 1, Vocab_Size) -> (Vocab_Size)\n",
    "                log_probs = torch.log_softmax(output[:, -1, :], dim=-1).squeeze()\n",
    "\n",
    "            topk_probs, topk_idxs = torch.topk(log_probs, beam_size)\n",
    "\n",
    "            for k in range(beam_size):\n",
    "                idx = topk_idxs[k].item()\n",
    "                prob = topk_probs[k].item()\n",
    "                new_seq = seq + [idx]\n",
    "                new_score = score + prob # log_prob: log(a*b) = log(a) + log(b)\n",
    "                candidates.append((new_seq, new_score, False))\n",
    "\n",
    "        ordered = sorted(candidates, key=lambda x: x[1] / (len(x[0])**alpha) if not x[2] else x[1], reverse=True)\n",
    "        beam = [(seq, score) for seq, score, _ in ordered[:beam_size]]\n",
    "\n",
    "        if all(seq[-1] == eos_idx for seq, _ in beam):\n",
    "            break\n",
    "\n",
    "    best_seq, best_score = beam[0]\n",
    "    trg_tokens = [trg_vocab.itos[i] for i in best_seq]\n",
    "\n",
    "    if '<eos>' in trg_tokens:\n",
    "        return trg_tokens[1:trg_tokens.index('<eos>')]\n",
    "    else:\n",
    "        return trg_tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7d5dd01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:19:21.207996Z",
     "iopub.status.busy": "2025-12-16T18:19:21.207737Z",
     "iopub.status.idle": "2025-12-16T18:26:47.019580Z",
     "shell.execute_reply": "2025-12-16T18:26:47.018883Z"
    },
    "papermill": {
     "duration": 446.568417,
     "end_time": "2025-12-16T18:26:47.020729",
     "exception": false,
     "start_time": "2025-12-16T18:19:20.452312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BLEU (Beam Size=3)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1268/1268 [07:25<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score with Beam Search: 25.13\n"
     ]
    }
   ],
   "source": [
    "def calculate_bleu_beam(data, src_vocab, trg_vocab, model, device, beam_size=3):\n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "\n",
    "    print(f\"Calculating BLEU (Beam Size={beam_size})...\")\n",
    "\n",
    "    for i, example in tqdm(enumerate(data), total=len(data)):\n",
    "        src = example['src']\n",
    "        trg = example['trg']\n",
    "\n",
    "        pred_trg = translate_sentence_beam(src, src_vocab, trg_vocab, model, device, beam_size=beam_size)\n",
    "\n",
    "        if isinstance(trg, str):\n",
    "            trg_tokenized = trg_vocab.tokenizer(trg)\n",
    "        else:\n",
    "            trg_tokenized = trg\n",
    "\n",
    "        pred_trgs.append(pred_trg)\n",
    "        trgs.append([trg_tokenized])\n",
    "\n",
    "    score = corpus_bleu(trgs, pred_trgs)\n",
    "    return score\n",
    "\n",
    "new_bleu = calculate_bleu_beam(test_data, src_vocab, trg_vocab, model, DEVICE, beam_size=3)\n",
    "print(f'BLEU Score with Beam Search: {new_bleu*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158b3e4",
   "metadata": {
    "papermill": {
     "duration": 0.785578,
     "end_time": "2025-12-16T18:26:48.718936",
     "exception": false,
     "start_time": "2025-12-16T18:26:47.933358",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Optim 2: Vietnamese Seg + BPE tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3551d6fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:26:50.428548Z",
     "iopub.status.busy": "2025-12-16T18:26:50.428293Z",
     "iopub.status.idle": "2025-12-16T18:26:50.476871Z",
     "shell.execute_reply": "2025-12-16T18:26:50.476073Z"
    },
    "papermill": {
     "duration": 0.874314,
     "end_time": "2025-12-16T18:26:50.478783",
     "exception": false,
     "start_time": "2025-12-16T18:26:49.604469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf611878",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:26:52.171115Z",
     "iopub.status.busy": "2025-12-16T18:26:52.170407Z",
     "iopub.status.idle": "2025-12-16T18:26:52.174690Z",
     "shell.execute_reply": "2025-12-16T18:26:52.173954Z"
    },
    "papermill": {
     "duration": 0.788958,
     "end_time": "2025-12-16T18:26:52.175718",
     "exception": false,
     "start_time": "2025-12-16T18:26:51.386760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_list_to_file(data_list, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for line in data_list:\n",
    "            f.write(str(line).strip() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "807b0baf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:26:53.958686Z",
     "iopub.status.busy": "2025-12-16T18:26:53.957947Z",
     "iopub.status.idle": "2025-12-16T18:26:53.962499Z",
     "shell.execute_reply": "2025-12-16T18:26:53.961932Z"
    },
    "papermill": {
     "duration": 0.889488,
     "end_time": "2025-12-16T18:26:53.963609",
     "exception": false,
     "start_time": "2025-12-16T18:26:53.074121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_bpe(files, vocab_size=10000, save_path=\"bpe_tokenizer.json\"):\n",
    "    # 1. Tokenizer BPE\n",
    "    tokenizer = Tokenizer(BPE(unk_token=\"<unk>\"))\n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "    # 2. Trainer\n",
    "    trainer = BpeTrainer(\n",
    "        vocab_size=vocab_size,\n",
    "        special_tokens=[\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"],\n",
    "        min_frequency=2,\n",
    "        show_progress=True\n",
    "    )\n",
    "\n",
    "    # 3. Train\n",
    "    print(f\"Training BPE tokenizer in {files}...\")\n",
    "    tokenizer.train(files, trainer)\n",
    "\n",
    "    tokenizer.save(save_path)\n",
    "    print(f\"Saved tokenizer to {save_path}\")\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b0ba7f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:26:55.642837Z",
     "iopub.status.busy": "2025-12-16T18:26:55.642310Z",
     "iopub.status.idle": "2025-12-16T18:26:55.647639Z",
     "shell.execute_reply": "2025-12-16T18:26:55.647070Z"
    },
    "papermill": {
     "duration": 0.899306,
     "end_time": "2025-12-16T18:26:55.648688",
     "exception": false,
     "start_time": "2025-12-16T18:26:54.749382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BPEVocabulary:\n",
    "    def __init__(self, tokenizer_path):\n",
    "        # Load tokenizer\n",
    "        self.tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "\n",
    "        self.pad_token_id = self.tokenizer.token_to_id(\"<pad>\")\n",
    "        self.sos_token_id = self.tokenizer.token_to_id(\"<sos>\")\n",
    "        self.eos_token_id = self.tokenizer.token_to_id(\"<eos>\")\n",
    "        self.unk_token_id = self.tokenizer.token_to_id(\"<unk>\")\n",
    "\n",
    "        # Mapping for model (stoi, itos)\n",
    "        self.stoi = self.tokenizer.get_vocab()\n",
    "        self.itos = {v: k for k, v in self.stoi.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tokenizer.get_vocab_size()\n",
    "\n",
    "    def numericalize(self, text):\n",
    "        # encode BPE tự tách từ\n",
    "        # add_special_tokens=False, đã thêm SOS/EOS thủ công ở Dataset\n",
    "        encoding = self.tokenizer.encode(text)\n",
    "        return encoding.ids\n",
    "\n",
    "    def decode(self, indices):\n",
    "        return self.tokenizer.decode(indices, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0e8c0b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:26:57.237936Z",
     "iopub.status.busy": "2025-12-16T18:26:57.237632Z",
     "iopub.status.idle": "2025-12-16T18:27:02.136134Z",
     "shell.execute_reply": "2025-12-16T18:27:02.135164Z"
    },
    "papermill": {
     "duration": 5.696192,
     "end_time": "2025-12-16T18:27:02.137556",
     "exception": false,
     "start_time": "2025-12-16T18:26:56.441364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyvi\r\n",
      "  Downloading pyvi-0.1.1-py2.py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from pyvi) (1.2.2)\r\n",
      "Collecting sklearn-crfsuite (from pyvi)\r\n",
      "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (1.15.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (1.5.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (3.6.0)\r\n",
      "Collecting python-crfsuite>=0.9.7 (from sklearn-crfsuite->pyvi)\r\n",
      "  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\r\n",
      "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite->pyvi) (4.67.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (2.4.1)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->pyvi) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->pyvi) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->pyvi) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn->pyvi) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn->pyvi) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn->pyvi) (2024.2.0)\r\n",
      "Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\r\n",
      "Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\r\n",
      "Successfully installed python-crfsuite-0.9.11 pyvi-0.1.1 sklearn-crfsuite-0.5.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fee283e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:27:03.801461Z",
     "iopub.status.busy": "2025-12-16T18:27:03.800879Z",
     "iopub.status.idle": "2025-12-16T18:27:03.855599Z",
     "shell.execute_reply": "2025-12-16T18:27:03.854821Z"
    },
    "papermill": {
     "duration": 0.838952,
     "end_time": "2025-12-16T18:27:03.856851",
     "exception": false,
     "start_time": "2025-12-16T18:27:03.017899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "def segment_vietnamese_data(data):\n",
    "    processed_data = []\n",
    "    print(\"Đang tách từ tiếng Việt (Word Segmentation)...\")\n",
    "\n",
    "    for item in tqdm(data):\n",
    "        src = item['src']\n",
    "        trg = item['trg']\n",
    "\n",
    "        # Tách từ tiếng Việt: \"Học sinh đi học\" -> \"Học_sinh đi học\"\n",
    "        trg_segmented = ViTokenizer.tokenize(trg)\n",
    "\n",
    "        processed_data.append({'src': src, 'trg': trg_segmented})\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "223d9915",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:27:05.536369Z",
     "iopub.status.busy": "2025-12-16T18:27:05.535699Z",
     "iopub.status.idle": "2025-12-16T18:27:46.261567Z",
     "shell.execute_reply": "2025-12-16T18:27:46.260712Z"
    },
    "papermill": {
     "duration": 41.520318,
     "end_time": "2025-12-16T18:27:46.262892",
     "exception": false,
     "start_time": "2025-12-16T18:27:04.742574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tách từ tiếng Việt (Word Segmentation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119849/119849 [00:36<00:00, 3315.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tách từ tiếng Việt (Word Segmentation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13317/13317 [00:04<00:00, 3227.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tách từ tiếng Việt (Word Segmentation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1268/1268 [00:00<00:00, 2864.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gốc: và sự chú ý này sẽ giúp thúc đẩy tình trạng , cũng như tất cả các mặt khác của vấn đề . \"\n",
      "Seg : và sự chú_ý này sẽ giúp thúc_đẩy tình_trạng , cũng như tất_cả các mặt_khác của vấn_đề . \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data_seg = segment_vietnamese_data(train_data)\n",
    "valid_data_seg = segment_vietnamese_data(valid_data)\n",
    "test_data_seg  = segment_vietnamese_data(test_data)\n",
    "\n",
    "print(f\"\\nGốc: {train_data[0]['trg']}\")\n",
    "print(f\"Seg : {train_data_seg[0]['trg']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea6798e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:27:47.996483Z",
     "iopub.status.busy": "2025-12-16T18:27:47.995645Z",
     "iopub.status.idle": "2025-12-16T18:27:51.309245Z",
     "shell.execute_reply": "2025-12-16T18:27:51.308486Z"
    },
    "papermill": {
     "duration": 4.235774,
     "end_time": "2025-12-16T18:27:51.310551",
     "exception": false,
     "start_time": "2025-12-16T18:27:47.074777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BPE tokenizer in ['temp_seg_src.txt']...\n",
      "\n",
      "\n",
      "\n",
      "Saved tokenizer to bpe_en_seg.json\n",
      "Training BPE tokenizer in ['temp_seg_trg.txt']...\n",
      "\n",
      "\n",
      "\n",
      "Saved tokenizer to bpe_vi_seg.json\n"
     ]
    }
   ],
   "source": [
    "save_list_to_file([x['src'] for x in train_data_seg], 'temp_seg_src.txt')\n",
    "save_list_to_file([x['trg'] for x in train_data_seg], 'temp_seg_trg.txt')\n",
    "\n",
    "src_tokenizer_seg = train_bpe(['temp_seg_src.txt'], vocab_size=10000, save_path=\"bpe_en_seg.json\")\n",
    "trg_tokenizer_seg = train_bpe(['temp_seg_trg.txt'], vocab_size=10000, save_path=\"bpe_vi_seg.json\")\n",
    "\n",
    "src_vocab_seg = BPEVocabulary(\"bpe_en_seg.json\")\n",
    "trg_vocab_seg = BPEVocabulary(\"bpe_vi_seg.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5790aa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:27:53.034178Z",
     "iopub.status.busy": "2025-12-16T18:27:53.033515Z",
     "iopub.status.idle": "2025-12-16T18:27:53.037282Z",
     "shell.execute_reply": "2025-12-16T18:27:53.036697Z"
    },
    "papermill": {
     "duration": 0.916604,
     "end_time": "2025-12-16T18:27:53.038367",
     "exception": false,
     "start_time": "2025-12-16T18:27:52.121763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds_seg = ManualDataset(train_data_seg, src_vocab_seg, trg_vocab_seg)\n",
    "valid_ds_seg = ManualDataset(valid_data_seg, src_vocab_seg, trg_vocab_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b999a506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:27:54.747617Z",
     "iopub.status.busy": "2025-12-16T18:27:54.747341Z",
     "iopub.status.idle": "2025-12-16T18:27:54.751917Z",
     "shell.execute_reply": "2025-12-16T18:27:54.751365Z"
    },
    "papermill": {
     "duration": 0.813135,
     "end_time": "2025-12-16T18:27:54.752881",
     "exception": false,
     "start_time": "2025-12-16T18:27:53.939746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader_seg = DataLoader(train_ds_seg, batch_size=BATCH_SIZE, shuffle=True, collate_fn=Collate(pad_idx=src_vocab_seg.pad_token_id))\n",
    "valid_loader_seg = DataLoader(valid_ds_seg, batch_size=BATCH_SIZE, shuffle=False, collate_fn=Collate(pad_idx=src_vocab_seg.pad_token_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0eff829",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:27:56.471610Z",
     "iopub.status.busy": "2025-12-16T18:27:56.471057Z",
     "iopub.status.idle": "2025-12-16T18:27:56.643909Z",
     "shell.execute_reply": "2025-12-16T18:27:56.643313Z"
    },
    "papermill": {
     "duration": 0.992384,
     "end_time": "2025-12-16T18:27:56.645301",
     "exception": false,
     "start_time": "2025-12-16T18:27:55.652917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_seg = Transformer(\n",
    "    src_vocab_size=len(src_vocab_seg),\n",
    "    trg_vocab_size=len(trg_vocab_seg),\n",
    "    src_pad_idx=src_vocab_seg.pad_token_id,\n",
    "    trg_pad_idx=trg_vocab_seg.pad_token_id,\n",
    "    d_model=D_MODEL,\n",
    "    n_head=N_HEAD,\n",
    "    n_layer=N_LAYER,\n",
    "    d_ff=D_FF,\n",
    "    dropout=DROPOUT,\n",
    "    device=DEVICE\n",
    ").to(DEVICE)\n",
    "\n",
    "model_seg.apply(initialize_weights)\n",
    "\n",
    "# --- Optimizer & Scheduler ---\n",
    "optimizer = optim.Adam(model_seg.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "# Loss Function\n",
    "# ignore_index=0 ignore loss <pad> token\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=src_vocab_seg.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae7b90f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T18:27:58.373642Z",
     "iopub.status.busy": "2025-12-16T18:27:58.373375Z",
     "iopub.status.idle": "2025-12-16T19:13:01.449679Z",
     "shell.execute_reply": "2025-12-16T19:13:01.448874Z"
    },
    "papermill": {
     "duration": 2703.881211,
     "end_time": "2025-12-16T19:13:01.450883",
     "exception": false,
     "start_time": "2025-12-16T18:27:57.569672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:22<00:00, 28.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model_seg (Val Loss: 4.784)\n",
      "Epoch: 01 | Time: 4m 31s\n",
      "\tTrain Loss: 5.444 | Train PPL: 231.393\n",
      "\t Val. Loss: 4.784 |  Val. PPL: 119.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:21<00:00, 28.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model_seg (Val Loss: 4.055)\n",
      "Epoch: 02 | Time: 4m 30s\n",
      "\tTrain Loss: 4.490 | Train PPL:  89.128\n",
      "\t Val. Loss: 4.055 |  Val. PPL:  57.681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:20<00:00, 28.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model_seg (Val Loss: 3.635)\n",
      "Epoch: 03 | Time: 4m 30s\n",
      "\tTrain Loss: 3.940 | Train PPL:  51.421\n",
      "\t Val. Loss: 3.635 |  Val. PPL:  37.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:20<00:00, 28.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model_seg (Val Loss: 3.379)\n",
      "Epoch: 04 | Time: 4m 30s\n",
      "\tTrain Loss: 3.587 | Train PPL:  36.120\n",
      "\t Val. Loss: 3.379 |  Val. PPL:  29.332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:21<00:00, 28.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model_seg (Val Loss: 3.192)\n",
      "Epoch: 05 | Time: 4m 30s\n",
      "\tTrain Loss: 3.356 | Train PPL:  28.667\n",
      "\t Val. Loss: 3.192 |  Val. PPL:  24.337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:23<00:00, 28.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model_seg (Val Loss: 3.075)\n",
      "Epoch: 06 | Time: 4m 32s\n",
      "\tTrain Loss: 3.189 | Train PPL:  24.259\n",
      "\t Val. Loss: 3.075 |  Val. PPL:  21.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:19<00:00, 28.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model_seg (Val Loss: 2.985)\n",
      "Epoch: 07 | Time: 4m 28s\n",
      "\tTrain Loss: 3.058 | Train PPL:  21.285\n",
      "\t Val. Loss: 2.985 |  Val. PPL:  19.782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:20<00:00, 28.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model_seg (Val Loss: 2.918)\n",
      "Epoch: 08 | Time: 4m 29s\n",
      "\tTrain Loss: 2.956 | Train PPL:  19.217\n",
      "\t Val. Loss: 2.918 |  Val. PPL:  18.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:19<00:00, 28.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model_seg (Val Loss: 2.866)\n",
      "Epoch: 09 | Time: 4m 28s\n",
      "\tTrain Loss: 2.869 | Train PPL:  17.619\n",
      "\t Val. Loss: 2.866 |  Val. PPL:  17.570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7491/7491 [04:19<00:00, 28.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model_seg (Val Loss: 2.833)\n",
      "Epoch: 10 | Time: 4m 28s\n",
      "\tTrain Loss: 2.801 | Train PPL:  16.453\n",
      "\t Val. Loss: 2.833 |  Val. PPL:  16.991\n"
     ]
    }
   ],
   "source": [
    "# --- MAIN LOOP ---\n",
    "CLIP = 1\n",
    "best_valid_loss = float('inf')\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "train_ppls = []\n",
    "valid_ppls = []\n",
    "\n",
    "print(f\"Start Training on {DEVICE}...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train_epoch(model_seg, train_loader_seg, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model_seg, valid_loader_seg, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = divmod(end_time - start_time, 60)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    train_ppls.append(math.exp(train_loss))\n",
    "    valid_ppls.append(math.exp(valid_loss))\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model_seg.state_dict(), 'transformer-model_seg.pt')\n",
    "        print(f\"Saved model_seg (Val Loss: {valid_loss:.3f})\")\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {int(epoch_mins)}m {int(epoch_secs)}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f860931",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:13:05.107651Z",
     "iopub.status.busy": "2025-12-16T19:13:05.107161Z",
     "iopub.status.idle": "2025-12-16T19:13:05.116372Z",
     "shell.execute_reply": "2025-12-16T19:13:05.115797Z"
    },
    "papermill": {
     "duration": 1.818744,
     "end_time": "2025-12-16T19:13:05.117532",
     "exception": false,
     "start_time": "2025-12-16T19:13:03.298788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer\n",
    "\n",
    "def translate_final(sentence, src_vocab, trg_vocab, model, device, max_len=50, beam_size=3):\n",
    "    model.eval()\n",
    "    \n",
    "    if isinstance(sentence, str):\n",
    "        src_indexes = [src_vocab.sos_token_id] + src_vocab.numericalize(sentence) + [src_vocab.eos_token_id]\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "    src_mask = model.make_src_mask(src_tensor)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        enc_src = model.src_embedding(src_tensor)\n",
    "        for layer in model.encoder_layers:\n",
    "            enc_src = layer(enc_src, src_mask)\n",
    "\n",
    "    beam = [([trg_vocab.sos_token_id], 0.0)]\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        candidates = []\n",
    "        for seq, score in beam:\n",
    "            if seq[-1] == trg_vocab.eos_token_id:\n",
    "                candidates.append((seq, score, True))\n",
    "                continue\n",
    "            \n",
    "            trg_tensor = torch.LongTensor(seq).unsqueeze(0).to(device)\n",
    "            trg_mask = model.make_trg_mask(trg_tensor)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = model.trg_embedding(trg_tensor)\n",
    "                for layer in model.decoder_layers:\n",
    "                    output = layer(output, enc_src, trg_mask, src_mask)\n",
    "                output = model.fc_out(output)\n",
    "                log_probs = torch.log_softmax(output[:, -1, :], dim=-1).squeeze()\n",
    "            \n",
    "            topk_probs, topk_idxs = torch.topk(log_probs, beam_size)\n",
    "            \n",
    "            for k in range(beam_size):\n",
    "                idx = topk_idxs[k].item()\n",
    "                prob = topk_probs[k].item()\n",
    "                candidates.append((seq + [idx], score + prob, False))\n",
    "        # Length penalty\n",
    "        alpha = 0.7\n",
    "        ordered = sorted(candidates, key=lambda x: x[1] / (len(x[0])**alpha), reverse=True)\n",
    "        beam = [(s, sc) for s, sc, _ in ordered[:beam_size]]\n",
    "        \n",
    "        if all(s[-1] == trg_vocab.eos_token_id for s, _ in beam):\n",
    "            break\n",
    "            \n",
    "    best_seq = beam[0][0]\n",
    "    segmented_text = trg_vocab.tokenizer.decode(best_seq, skip_special_tokens=True)\n",
    "    final_text = segmented_text.replace(\"_\", \" \")\n",
    "    \n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4ec03aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:13:08.877553Z",
     "iopub.status.busy": "2025-12-16T19:13:08.876927Z",
     "iopub.status.idle": "2025-12-16T19:19:54.135104Z",
     "shell.execute_reply": "2025-12-16T19:19:54.134362Z"
    },
    "papermill": {
     "duration": 407.078904,
     "end_time": "2025-12-16T19:19:54.136272",
     "exception": false,
     "start_time": "2025-12-16T19:13:07.057368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tính BLEU (Seg + BPE + Beam k=3)...\n",
      "Src : when i was little , i thought my country was the best on the planet , and i grew up singing a song called \" nothing to envy . \"\n",
      "Ref : khi tôi còn nhỏ , tôi nghĩ rằng bắctriều tiên là đất nước tốt nhất trên thế giới và tôi thường hát bài \" chúng ta chẳng có gì phải ghen tị . \"\n",
      "Pred: khi tôi còn nhỏ , tôi nghĩ đất nước tôi là người tốt nhất trên hành tinh này , và tôi lớn lên hát một bài hát có tên gọi là \" không có gì với sự sợ hãi . \"\n",
      "--------------------\n",
      "Src : i would have told you myself that i was the last person on earth who would stay with a man who beats me , but in fact i was a very typical victim because of my age .\n",
      "Ref : tôi đã tự nhủ bản thân mình , tôi là người còn lại trên trái đất chung sống với người đàn ông đã đánh mình , nhưng thật ra , tôi là một nạn nhân điển hình do độ tuổi của tôi .\n",
      "Pred: tôi sẽ nói với các bạn rằng tôi là người cuối cùng trên trái đất , những người sẽ ở lại với một người đàn ông đánh tôi , nhưng thực ra tôi là một nạn nhân rất điển hình bởi tuổi của tôi .\n",
      "--------------------\n",
      "Src : hi . this is my mobile phone .\n",
      "Ref : xin chào . đây là chiếc điện thoại di động của tôi .\n",
      "Pred: chào . đây là điện thoại di động của tôi .\n",
      "--------------------\n",
      "Src : thank you .\n",
      "Ref : cảm ơn quý vị .\n",
      "Pred: cảm ơn .\n",
      "--------------------\n",
      "Src : it 's 150 feet by 10 feet .\n",
      "Ref : nó rộng hơn 3m , dài 50m .\n",
      "Pred: nó có khoảng 150 feet .\n",
      "--------------------\n",
      "Src : so planning has this blind spot .\n",
      "Ref : vậy nên hoạch định có một điểm mù này .\n",
      "Pred: vì vậy kế hoạch có một điểm mù .\n",
      "--------------------\n",
      "Src : each cubicle is dark and dingy , identified with a painted number on the wall , and partitioned by plywood and a curtain .\n",
      "Ref : phòng ngủ nào cũng bẩn thỉu và tối om , được nhận ra bởi con số sơn trên tường phân cách bởi miếng ván ép và rèm che .\n",
      "Pred: mỗi cái hộp này là tối và kéo , được xác định bởi một con số vẽ trên tường , và một phần bằng cách làm bằng gỗ , và một cái ống .\n",
      "--------------------\n",
      "\n",
      ">> FINAL BLEU SCORE (Optimized): 25.36\n"
     ]
    }
   ],
   "source": [
    "def calculate_bleu_final_optimized(data_raw, src_vocab, trg_vocab, model, device, beam_size=3):\n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "    \n",
    "    print(f\"Đang tính BLEU (Seg + BPE + Beam k={beam_size})...\")\n",
    "    \n",
    "    for i, example in enumerate(data_raw):\n",
    "        src = example['src']\n",
    "        trg = example['trg'] # \"Học sinh đi học\"\n",
    "        \n",
    "        # Model -> \"Học_sinh đi học\" -> replace -> \"Học sinh đi học\"\n",
    "        pred_sent = translate_final(src, src_vocab, trg_vocab, model, device, beam_size=beam_size)\n",
    "        \n",
    "        pred_trgs.append(pred_sent.split())\n",
    "        trgs.append([trg.split()])\n",
    "        \n",
    "        if i % 200 == 0:\n",
    "            print(f\"Src : {src}\")\n",
    "            print(f\"Ref : {trg}\")\n",
    "            print(f\"Pred: {pred_sent}\")\n",
    "            print(\"-\" * 20)\n",
    "            \n",
    "    score = corpus_bleu(trgs, pred_trgs)\n",
    "    return score\n",
    "\n",
    "\n",
    "final_bleu = calculate_bleu_final_optimized(test_data, src_vocab_seg, trg_vocab_seg, model_seg, DEVICE, beam_size=3)\n",
    "print(f\"\\n>> FINAL BLEU SCORE (Optimized): {final_bleu*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b475f74e",
   "metadata": {
    "papermill": {
     "duration": 4.602521,
     "end_time": "2025-12-16T22:08:29.148363",
     "exception": false,
     "start_time": "2025-12-16T22:08:24.545842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9033305,
     "sourceId": 14171788,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9033760,
     "sourceId": 14172424,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16491.161438,
   "end_time": "2025-12-16T22:08:36.224646",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-16T17:33:45.063208",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
